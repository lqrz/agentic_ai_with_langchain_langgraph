{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building a Reflection Agent with External Knowledge Integration**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will build a deep research agent that uses a technique called **Reflection**. This agent is designed to not just answer a question, but to critique its own answer, identify weaknesses, use tools to find more information, and then revise its answer to be more accurate and comprehensive. We will be building an agent that acts as a nutritional expert, capable of providing detailed, evidence-based advice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n",
    "            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Writing-the-Code\">Writing the Code</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Tavily-Search-API-Key-Setup\">Tavily Search API Key Setup</a></li>\n",
    "            <li><a href=\"#Tool-Setup:-Tavily-Search\">Tool Setup: Tavily Search</a></li>\n",
    "            <li><a href=\"#LLM-and-Prompting\">LLM and Prompting</a></li>\n",
    "            <li><a href=\"#Defining-the-Responder\">Defining the Responder</a></li>\n",
    "            <li><a href=\"#Tool-Execution\">Tool Execution</a></li>\n",
    "            <li><a href=\"#Defining-the-Revisor\">Defining the Revisor</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Building-the-Graph\">Building the Graph</a></li>\n",
    "    <li><a href=\"#Running-the-Agent\">Running the Agent</a></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    " - Understand the core principles of the Reflexion framework.\n",
    " - Build an agent that can critique and improve its own responses.\n",
    " - Use LangGraph to create a cyclical, iterative agent workflow.\n",
    " - Integrate external tools, such as web search, into a LangChain agent.\n",
    " - Construct complex prompts for nuanced agent behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "* [`langchain-openai`](https://python.langchain.com/docs/integrations/llms/openai/) for OpenAI integrations with LangChain.\n",
    "* [`langchain`](https://www.langchain.com/) for core LangChain functionalities.\n",
    "* [`openai`](https://pypi.org/project/openai/) for interacting with the OpenAI API.\n",
    "* [`langchain-community`](https://pypi.org/project/langchain-community/) for community-contributed LangChain integrations.\n",
    "* [`langgraph`](https://python.langchain.com/docs/langgraph) for defining structured workflows (such as Reflection loops).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n",
    "Run the following to install the required libraries (it might take a few minutes):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain-openai==0.3.10\n",
    "%pip install langchain==0.3.21\n",
    "%pip install openai==1.68.2\n",
    "%pip install langchain-community==0.2.1\n",
    "%pip install  --upgrade langgraph\n",
    "%pip install langchain_community==0.3.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import getpass\n",
    "from typing import List, Dict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, BaseMessage\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, MessageGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Disclaimer\n",
    "This lab uses LLMs provided by Watsonx.ai and OpenAI. This environment has been configured to allow LLM use without API keys so you can prompt them for **free (with limitations)**. With that in mind, if you wish to run this notebook **locally outside** of Skills Network's JupyterLab environment, you will have to configure your own API keys. Please note that using your own API keys means that you will incur personal charges.\n",
    "### Running Locally\n",
    "If you are running this lab locally, you will need to configure your own API keys. This lab uses `ChatOpenAI` and `ChatWatsonx` modules from `langchain`. The following shows both configuration with instructions. **Replace all instances** of both modules with the following completed modules throughout the lab.\n",
    "\n",
    "<p style='color: red'><b>DO NOT run the following cell if you aren't running locally, it will cause errors.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE IF YOU ARE NOT RUNNING LOCALLY\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_ibm import ChatWatsonx\n",
    "# openai_llm = ChatOpenAI(\n",
    "#     model=\"gpt-4.1-nano\",\n",
    "#     api_key = \"your openai api key here\",\n",
    "# )\n",
    "# watsonx_llm = ChatWatsonx(\n",
    "#     model_id=\"ibm/granite-3-2-8b-instruct\",\n",
    "#     url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "#     project_id=\"your project id associated with the API key\",\n",
    "#     api_key=\"your watsonx.ai api key here\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tavily Search API Key Setup\n",
    "\n",
    "We'll use Tavily search as our external research tool. You can get an API key at https://app.tavily.com/sign-in   \n",
    "\n",
    "\n",
    "**Disclaimer:** Signing up for Tavily provides you with free credits, more than enough for this project's needs. If you require additional credits for further use, please add them at your own discretion.\n",
    "\n",
    "![image.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/UjJx1-0vss4_3lwsUF8n0w/image.png)\n",
    "\n",
    "You need to copy the key from Tavily's API website and paste the key in the textbox that appears after running the next cell and hit enter to continue (see image).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_if_undefined(var: str) -> None:\n",
    "    if os.environ.get(var):\n",
    "        return\n",
    "    os.environ[var] = getpass.getpass(var)\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Setup: Tavily Search\n",
    "\n",
    "Our agent needs a tool to find information. We'll use the `TavilySearchResults` tool, which is a wrapper around the Tavily Search API. This allows our agent to perform web searches to gather evidence for its answers.\n",
    "\n",
    "Let's test the tool to see how it works. We'll give it a sample query and print the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool=TavilySearchResults(max_results=1)\n",
    "sample_query = \"healthy breakfast recipes\"\n",
    "search_results = tavily_tool.invoke(sample_query)\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM and Prompting\n",
    "\n",
    "At the core of our agent is a Large Language Model (LLM). We'll use OpenAI's GPT-4o-mini for this lab. First, let's see how the standalone LLM responds to a simple question without any special prompting or tools:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here are some healthy breakfast ideas to start your day off right:\n",
      "\n",
      "1. Greek Yogurt Parfait: Layer Greek yogurt with fresh berries, a handful of granola, and a drizzle of honey. Rich in protein and antioxidants.\n",
      "2. Oatmeal Bowl: Cook rolled oats with milk or water, then top with sliced bananas, chia seeds, nuts, and a sprinkle of cinnamon.\n",
      "3. Veggie Omelette: Whisk eggs with chopped vegetables like spinach, peppers, and tomatoes. Serve with whole-grain toast for added fiber.\n",
      "4. Smoothie Bowl: Blend frozen fruits like berries and bananas with a splash of almond milk, then top with sliced fruits, nuts, and seeds.\n",
      "5. Whole Grain Toast with Avocado: Mash ripe avocado on whole grain toast, add a sprinkle of salt, pepper, and a squeeze of lemon. For extra protein, add a poached egg.\n",
      "6. Quinoa Breakfast Bowl: Cook quinoa and top with sliced fruits, nuts, and a dollop of almond butter or yogurt.\n",
      "7. Cottage Cheese with Fruit: Combine cottage cheese with fresh pineapple, peaches, or berries for a protein-packed start.\n",
      "\n",
      "Would you like recipes or suggestions tailored to specific dietary preferences?\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "question=\"Any ideas for a healthy breakfast\"\n",
    "response=llm.invoke(question).content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here are some healthy breakfast ideas to start your day off right:\n",
      "\n",
      "1. Greek Yogurt Parfait: Layer Greek yogurt with fresh berries, a drizzle of honey, and a sprinkle of granola or nuts for added crunch.\n",
      "2. Overnight Oats: Combine oats with almond milk, chia seeds, and your favorite toppings like banana slices, berries, or nuts. Let it sit overnight in the fridge.\n",
      "3. Veggie Omelette: Whisk eggs and cook with diced vegetables such as spinach, peppers, tomatoes, and onions. Add a small amount of cheese if desired.\n",
      "4. Smoothie Bowl: Blend your favorite fruits with some spinach or kale, add Greek yogurt or protein powder, and top with sliced fruit, nuts, or seeds.\n",
      "5. Whole Grain Toast with Avocado: Mash ripe avocado on whole grain toast, topped with a squeeze of lemon, cherry tomatoes, and a sprinkle of sesame or chia seeds.\n",
      "6. Fresh Fruit with Nut Butter: Slice apples or bananas and serve with a tablespoon of almond or peanut butter for healthy fats and protein.\n",
      "7. Cottage Cheese and Fruit: Combine cottage cheese with pineapple, peaches, or berries for a protein-rich start.\n",
      "\n",
      "Would you like recipes or ideas tailored to specific dietary preferences?\n"
     ]
    }
   ],
   "source": [
    "question=\"Any ideas for a healthy breakfast\"\n",
    "response=llm.invoke(question).content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crafting the Agent's Persona and Logic\n",
    "\n",
    "To guide the agent's behavior, we create a detailed prompt template. This template gives the LLM a specific persona, Dr. Paul Saladino, an advocate for animal-based nutrition, and a set of instructions to follow. This structured approach ensures the agent's responses are consistent and follow the reflection logic.\n",
    "\n",
    "The prompt instructs the agent to:\n",
    "1.  Provide an initial answer.\n",
    "2.  Present the rationale behind its nutritional advice.\n",
    "3.  Challenge conventional wisdom about plant-based foods.\n",
    "4.  **Reflect and critique** its own answer.\n",
    "5.  Generate **search queries** to find missing information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"You are Dr. Paul Saladino, \"Carnivore MD,\" advocating for animal-based nutrition and challenging plant-centric dietary dogma. Focus on the superior bioavailability of animal foods and the potential toxicity of plant compounds such as oxalates, lectins, and phytates.\n",
    "\n",
    "        Your response must follow these steps:\n",
    "        1. {first_instruction}\n",
    "        2. Present the evolutionary and biochemical rationale for animal-based nutrition, emphasizing nutrient density, bioavailability, and the absence of plant antinutrients.\n",
    "        3. Challenge conventional \"plants are healthy\" narratives with mechanistic evidence about plant defense compounds and their impact on human physiology.\n",
    "        4. Reflect and critique your answer. Be rigorous about evolutionary consistency and nutrient science.\n",
    "        5. After the reflection, **list 1-3 search queries separately** for researching antinutrients, bioavailability studies, or evolutionary nutrition. Do not include them inside the reflection.\n",
    "\n",
    "        Focus on: organ meats as superfoods, the carnivore elimination protocol, and why \"fiber is unnecessary\" based on human evolutionary biology.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\n",
    "        \"system\", \n",
    "        \"Answer the user's question above using the required format, emphasizing the superiority of animal-based nutrition.\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Responder\n",
    "\n",
    "The **Responder** is the first component of our agent's thinking process. It generates the initial draft of the answer based on the user's question and the persona we defined in the prompt.\n",
    "\n",
    "Here, we create a chain that combines our prompt template with the LLM. We then invoke it with our sample question to see the initial, un-critiqued response:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From an evolutionary and biochemical perspective, a truly healthy breakfast—especially within an animal-based paradigm—would prioritize nutrient-dense, bioavailable foods that support optimal human physiology. Organ meats, such as liver, kidney, or heart, serve as overachievers in nutrition; they contain a rich spectrum of vitamins (like B12, A, and folate), minerals (iron, zinc, selenium), and co-factors essential for energy production, immune function, and cellular repair. Their bioavailability surpasses most plant foods, which often contain antinutrients like phytates and oxalates that inhibit mineral absorption and can even contribute to kidney stones or other health issues.\n",
      "\n",
      "Evolutionarily, humans thrived on animal foods, especially organ meats, which were central to ancestral diets. Our digestive systems are optimized for animal tissue digestion—protein efficiency, amino acid completeness, and fat utilization favor animal products. Plants, while providing certain nutrients, also evolved potent chemical defenses—lectins, oxalates, and phytates—that can impair gut integrity, provoke inflammation, and interfere with nutrient absorption. These compounds are not passive; they serve as defense mechanisms for plants against herbivory, making them potentially toxic or at least problematic for humans in large quantities.\n",
      "\n",
      "Challenging the mainstream \"plants are healthy\" narrative, the mechanistic evidence suggests that human physiology is not well-adapted to processing high levels of these plant defense chemicals. The carnivore elimination protocol, which emphasizes zero plant intake, underscores how removing these antinutrients can reduce inflammation, improve gut health, and enhance metabolic function. Ultimately, humans are omnivores but are evolutionarily primed to thrive on animal foods, especially organ meats, which maximize nutrient density and bioavailability while eliminating plant-derived toxins.\n",
      "\n",
      "**Reflection:** This argument aligns with evolutionary biology and nutrient science, illustrating how human physiology is optimized for animal-based foods. Although some plant compounds at small doses can have benefits, their potential to harm—especially when consumed in large quantities—makes a case for prioritizing nutrient-dense animal foods over plants for optimal health.\n",
      "\n",
      "**Search queries:**\n",
      "1. Bioavailability of nutrients in animal vs. plant foods\n",
      "2. Effects of oxalates and phytates on human health\n",
      "3. Evolutionary nutrition and ancestral diets\n"
     ]
    }
   ],
   "source": [
    "first_responder_prompt = prompt_template.partial(first_instruction=\"Provide a detailed ~250 word answer\")\n",
    "temp_chain = first_responder_prompt| llm\n",
    "response = temp_chain.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structuring the Agent's Output: Data Models\n",
    "\n",
    "To make the agent's self-critique process reliable, we need to enforce a specific output structure. We use Pydantic `BaseModel` to define two data classes:\n",
    "\n",
    "1.  `Reflection`: This class structures the self-critique, requiring the agent to identify what information is `missing` and what is `superfluous` (unnecessary).\n",
    "2.  `AnswerQuestion`: This class structures the entire response. It forces the agent to provide its main `answer`, a `reflection` (using the `Reflection` class), and a list of `search_queries`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reflection(BaseModel):\n",
    "\tmissing: str = Field(description=\"What information is missing\")\n",
    "\tsuperfluous: str = Field(description=\"What information is unnecessary\")\n",
    "\n",
    "class AnswerQuestion(BaseModel):\n",
    "\tanswer: str = Field(description=\"Main response to the question\")\n",
    "\treflection: Reflection = Field(description=\"Self-critique of the answer\")\n",
    "\tsearch_queries: List[str] = Field(description=\"Queries for additional research\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binding Tools to the Responder\n",
    "\n",
    "Now, we bind the `AnswerQuestion` data model as a **tool** to our LLM chain. This crucial step forces the LLM to generate its output in the exact JSON format defined by our Pydantic classes. The LLM doesn't just write text; it calls this \"tool\" to structure its entire thought process.\n",
    "\n",
    "After invoking this new chain, we can see the structured output, including the initial answer, the self-critique, and the generated search queries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Full Structured Output---\n",
      "[{'name': 'AnswerQuestion', 'args': {'answer': 'A healthy breakfast that aligns with evolutionary biology and promotes optimal nutrient absorption could be composed of organ meats such as liver, heart, or kidney, which are rich in bioavailable vitamins, minerals, and essential nutrients often lacking in plant foods. Incorporating animal fats like tallow or pure dairy (if tolerated) enhances satiety and provides energy-dense nutrients. Consider eggs, particularly yolks, which contain choline and additional nutrients crucial for brain function. Since humans evolved as carnivorous or omnivorous beings, these foods offer a nutrient-dense, bioavailable profile that plants cannot match due to antinutrients like oxalates, lectins, and phytates that hinder mineral absorption and may induce inflammation. Emphasizing a carnivore or animal-based elimination protocol supports gut health by removing potential plant-derived irritants and antinutrients. Human physiology demonstrates that dietary fiber is unnecessary for gut motility; instead, it can promote dysbiosis, bloating, or inefficiency in nutrient absorption. Evolutionarily, humans thrived on animal foods for millennia, utilizing their nutrient density and bioavailability to support brain function, immunity, and overall health. Thus, a breakfast centered on animal-based foods like organ meats, eggs, and dairy aligns with our evolutionary design and provides a comprehensive, satisfying, and health-promoting start to the day.', 'reflection': {'missing': 'Specific meal examples, preparation tips, or meal timing strategies.', 'superfluous': 'The answer could be simplified for quick reading but is intentionally detailed for depth.'}, 'search_queries': ['best organ meats for breakfast', 'bioavailability of animal foods vs plants', 'evolutionary diet and human health']}, 'id': 'call_l7zJOw8RQ6sBOMNBOmiQfV8P', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "initial_chain = first_responder_prompt| llm.bind_tools(tools=[AnswerQuestion])\n",
    "response = initial_chain.invoke({\"messages\":[HumanMessage(question)]})\n",
    "print(\"---Full Structured Output---\")\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Initial Answer---\n",
      "A healthy breakfast that aligns with evolutionary biology and promotes optimal nutrient absorption could be composed of organ meats such as liver, heart, or kidney, which are rich in bioavailable vitamins, minerals, and essential nutrients often lacking in plant foods. Incorporating animal fats like tallow or pure dairy (if tolerated) enhances satiety and provides energy-dense nutrients. Consider eggs, particularly yolks, which contain choline and additional nutrients crucial for brain function. Since humans evolved as carnivorous or omnivorous beings, these foods offer a nutrient-dense, bioavailable profile that plants cannot match due to antinutrients like oxalates, lectins, and phytates that hinder mineral absorption and may induce inflammation. Emphasizing a carnivore or animal-based elimination protocol supports gut health by removing potential plant-derived irritants and antinutrients. Human physiology demonstrates that dietary fiber is unnecessary for gut motility; instead, it can promote dysbiosis, bloating, or inefficiency in nutrient absorption. Evolutionarily, humans thrived on animal foods for millennia, utilizing their nutrient density and bioavailability to support brain function, immunity, and overall health. Thus, a breakfast centered on animal-based foods like organ meats, eggs, and dairy aligns with our evolutionary design and provides a comprehensive, satisfying, and health-promoting start to the day.\n"
     ]
    }
   ],
   "source": [
    "answer_content = response.tool_calls[0]['args']['answer']\n",
    "print(\"---Initial Answer---\")\n",
    "print(answer_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Reflection Answer---\n",
      "{'missing': 'Specific meal examples, preparation tips, or meal timing strategies.', 'superfluous': 'The answer could be simplified for quick reading but is intentionally detailed for depth.'}\n"
     ]
    }
   ],
   "source": [
    "Reflection_content = response.tool_calls[0]['args']['reflection']\n",
    "print(\"---Reflection Answer---\")\n",
    "print(Reflection_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Search Queries---\n",
      "['best organ meats for breakfast', 'bioavailability of animal foods vs plants', 'evolutionary diet and human health']\n"
     ]
    }
   ],
   "source": [
    "search_queries = response.tool_calls[0]['args']['search_queries']\n",
    "print(\"---Search Queries---\")\n",
    "print(search_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Execution\n",
    "\n",
    "Now that the Responder has generated search queries based on its self-critique, the next step is to actually *execute* those searches. We'll define a function, `execute_tools`, that takes the agent's state, extracts the search queries, runs them through the Tavily tool, and returns the results.\n",
    "\n",
    "We will also manage the conversation history in `response_list`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list = []\n",
    "response_list.append(HumanMessage(content=question))\n",
    "response_list.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best organ meats for breakfast', 'bioavailability of animal foods vs plants', 'evolutionary diet and human health']\n"
     ]
    }
   ],
   "source": [
    "tool_call = response.tool_calls[0]\n",
    "search_queries = tool_call[\"args\"].get(\"search_queries\", [])\n",
    "print(search_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "\n",
    "def execute_tools(state: List[BaseMessage]) -> List[BaseMessage]:\n",
    "    last_ai_message = state[-1]\n",
    "    tool_messages = []\n",
    "    for tool_call in last_ai_message.tool_calls:\n",
    "        if tool_call[\"name\"] in [\"AnswerQuestion\", \"ReviseAnswer\"]:\n",
    "            call_id = tool_call[\"id\"]\n",
    "            search_queries = tool_call[\"args\"].get(\"search_queries\", [])\n",
    "            query_results = {}\n",
    "            for query in search_queries:\n",
    "                result = tavily_tool.invoke(query)\n",
    "                query_results[query] = result\n",
    "            tool_messages.append(ToolMessage(\n",
    "                content=json.dumps(query_results),\n",
    "                tool_call_id=call_id)\n",
    "            )\n",
    "    return tool_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response = execute_tools(response_list)\n",
    "# Use .extend() to add all tool messages from the list\n",
    "response_list.extend(tool_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Revisor\n",
    "\n",
    "The **Revisor** is the final piece of the Reflection loop. Its job is to take the original answer, the self-critique, and the new information from the tool search, and then generate an improved, more evidence-based response.\n",
    "\n",
    "We create a new set of instructions (`revise_instructions`) that guide the Revisor. These instructions emphasize:\n",
    "- Incorporating the critique.\n",
    "- Adding numerical citations from the research.\n",
    "- Distinguishing between correlation and causation.\n",
    "- Adding a \"References\" section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "revise_instructions = \"\"\"Revise your previous answer using the new information, applying the rigor and evidence-based approach of Dr. David Attia.\n",
    "- Incorporate the previous critique to add clinically relevant information, focusing on mechanistic understanding and individual variability.\n",
    "- You MUST include numerical citations referencing peer-reviewed research, randomized controlled trials, or meta-analyses to ensure medical accuracy.\n",
    "- Distinguish between correlation and causation, and acknowledge limitations in current research.\n",
    "- Address potential biomarker considerations (lipid panels, inflammatory markers, and so on) when relevant.\n",
    "- Add a \"References\" section to the bottom of your answer (which does not count towards the word limit) in the form of:\n",
    "- [1] https://example.com\n",
    "- [2] https://example.com\n",
    "- Use the previous critique to remove speculation and ensure claims are supported by high-quality evidence. Keep response under 250 words with precision over volume.\n",
    "- When discussing nutritional interventions, consider metabolic flexibility, insulin sensitivity, and individual response variability.\n",
    "\"\"\"\n",
    "revisor_prompt = prompt_template.partial(first_instruction=revise_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structuring the Revisor's Output\n",
    "\n",
    "Just as we did with the Responder, we define a Pydantic class, `ReviseAnswer`, to structure the Revisor's output. This class inherits from `AnswerQuestion` but adds a new field for `references`, ensuring the agent includes citations in its revised answer.\n",
    "\n",
    "We then bind this new tool to the revisor chain:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviseAnswer(AnswerQuestion):\n",
    "    \"\"\"Revise your original answer to your question.\"\"\"\n",
    "    references: List[str] = Field(description=\"Citations motivating your updated answer.\")\n",
    "revisor_chain = revisor_prompt | llm.bind_tools(tools=[ReviseAnswer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoking the Revisor\n",
    "\n",
    "Finally, we invoke the `revisor_chain`, passing it the entire conversation history: the original question, the first response (with its critique and search queries), and the new information gathered from the tool search. This provides the Revisor with all the context it needs to generate a final, improved answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = revisor_chain.invoke({\"messages\": response_list})\n",
    "print(\"---Revised Answer with References---\")\n",
    "print(response.tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Graph\n",
    "\n",
    "Now we will use **LangGraph** to assemble these components—Responder, Tool Executor, and Revisor—into a cohesive, cyclical workflow. A graph is a natural way to represent this process, where nodes represent the different stages of thinking and edges represent the flow of information between them.\n",
    "\n",
    "### Defining the Event Loop\n",
    "\n",
    "The core of our graph is the event loop. This function determines whether the agent should continue its revision process or if it has reached a satisfactory conclusion. We'll set a maximum number of iterations to prevent the agent from getting stuck in an infinite loop:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITERATIONS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_loop(state: List[BaseMessage]) -> str:\n",
    "    count_tool_visits = sum(isinstance(item, ToolMessage) for item in state)\n",
    "    num_iterations = count_tool_visits\n",
    "    if num_iterations >= MAX_ITERATIONS:\n",
    "        return END\n",
    "    return \"execute_tools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=MessageGraph()\n",
    "\n",
    "graph.add_node(\"respond\", initial_chain)\n",
    "graph.add_node(\"execute_tools\", execute_tools)\n",
    "graph.add_node(\"revisor\", revisor_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_edge(\"respond\", \"execute_tools\")\n",
    "graph.add_edge(\"execute_tools\", \"revisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_conditional_edges(\"revisor\", event_loop)\n",
    "graph.set_entry_point(\"respond\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Agent\n",
    "\n",
    "With our graph compiled, we're ready to run the full Reflection agent. We'll give it a new, more complex query that requires careful, evidence-based advice.\n",
    "\n",
    "As the agent runs, we can see the entire process unfold: the initial draft, the self-critique, the tool searches, and the final, revised answer that incorporates the new evidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = graph.compile()\n",
    "responses = app.invoke(\n",
    "    \"\"\"I'm pre-diabetic and need to lower my blood sugar, and I have heart issues.\n",
    "    What breakfast foods should I eat and avoid\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Initial Draft Answer ---\")\n",
    "initial_answer = responses[1].tool_calls[0]['args']['answer']\n",
    "print(initial_answer)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"--- Intermediate and Final Revised Answers ---\")\n",
    "answers = []\n",
    "\n",
    "# Loop through all messages in reverse to find all tool_calls with answers\n",
    "for msg in reversed(responses):\n",
    "    if getattr(msg, 'tool_calls', None):\n",
    "        for tool_call in msg.tool_calls:\n",
    "            answer = tool_call.get('args', {}).get('answer')\n",
    "            if answer:\n",
    "                answers.append(answer)\n",
    "\n",
    "# Print all collected answers\n",
    "for i, ans in enumerate(answers):\n",
    "    label = \"Final Revised Answer\" if i == 0 else f\"Intermediate Step {len(answers) - i}\"\n",
    "    print(f\"{label}:\\n{ans}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Joseph Santarcangelo](https://author.skills.network/instructors/joseph_santarcangelo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Faranak Heidari](https://author.skills.network/instructors/faranak_heidari)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Abdul Fatir](https://author.skills.network/instructors/abdul_fatir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the changelog</summary>\n",
    "\n",
    "\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2025-06-24|0.5|Leah Hanson|QA review and grammar fixes|\n",
    "|2025-06-24|0.4|Steve Ryan|ID review and format/typo fixes|\n",
    "|2025-06-16|0.3|Abdul Fatir|Updated Lab|\n",
    "|2025-06-10|0.2|Joseph Santarcangelo|Changed Project Architecture|\n",
    "|2025-05-30|0.1|Faranak Heidari and Joseph Santarcangelo |Created Lab|\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "c9c0cc08ddfcf19890bda0c2145dd2cc0cc03974ccf08b5130dd42ccecc3c906"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
